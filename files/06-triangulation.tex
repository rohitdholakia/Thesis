\chapter{Triangulation}
\label{chap:triangulation}

\anoop{some basic formatting issues: always put a space between word and open parenthesis; never put a space between word and final punctuation.}

\section{What is Triangulation?}
\label{sec:triangulation}
To explain the algorithm, lets first use an example from the previous chapter. We saw in the previous chapter that the sentence \mawuexample had two OOVs resolved after interpolating with a triangulated table. In other words, the direct system did not have any knowledge about two phrases, \emph{$y\grave{a}ng\acute{a}l\acute{a}\grave{a}$} and \emph{l$\acute{a}$kw$\acute{e}$}. We observe that in the source pivot table, we have 1 rule for the word \emph{$y\grave{a}ng\acute{a}l\acute{a}\grave{a}$}. \\

\indent
    \emph{$y\grave{a}ng\acute{a}l\acute{a}\grave{a}$} $|||$ la maladie $|||$ 0.285714 0.0926127 1 0.16 2.718\\

The french phrase ``la maladie'' has 215 translations in the Europarl table. We use all 215 options to compute feature values for new (\emph{$y\grave{a}ng\acute{a}l\acute{a}\grave{a}$}, tgt) translation pairs and select the top-\emph{n} and add it to the table. These steps are explained in a formal manner below. 



Consider a source language, \emph{s}, a target language, \emph{t}, and a pivot language \emph{i}. You have a little parallel data between \emph{s} and \emph{t} and believe that triangulation will increase the quality of translations between \emph{s} and \emph{t}. What steps one would follow to get the desired result ?

\begin{algorithm}
\caption{Vanilla Triangulation}
\label{algo:vanilla_triangulation}

\textbf{Input:} phrase table between \emph{s} and \emph{i}, p$_{s-i}$, \\
 phrase table between \emph{p} and \emph{t}, p$_{i-t}$,  \\
 \emph{n} for selecting top-n phrase pairs \\
\textbf{Output:} p$_{trian}$
\begin{algorithmic}[l]
\FORALL{(src, pivot) in top-\emph{n} p$_{s-i}$} \label{aline:common}
		\IF{pivot phrase in p$_{i-t}$} 

        \FOR{all (pivot, tgt) pairs in p$_{i-t}$}
        \STATE{compute feature values for (s, t)} \label{aline:computation}
        \ENDFOR
        \STATE{select top-\emph{n} src-target pair, add to p$_{trian}$} \label{aline:topn}
        \ENDIF
        \ENDFOR


%\ENDFOR
\end{algorithmic}

\end{algorithm}

The algorithm for triangulation is described in Algorithm~\ref{algo:vanilla_triangulation}. Having obtained new source target pairs by using the common pivot phrases in line~\ref{aline:common}, we proceed to compute the feature values for the new phrase pairs(line~\ref{aline:computation}). To minimize the noise, we only select the top-\emph{n} translations for any given source phrase(line~\ref{aline:topn}). Line~\ref{aline:common} reiterates the importance of having a source pivot corpus of reasonable size. The triangulated translation model is contingent upon common pivot phrases and without a reasonably-sized source pivot corpus, we cannot fully utilize the large pivot target corpus(2M Europarl sentences in this dissertation). Having generated a triangulated translation model, one can combine it with the existing baseline model in several ways(~\cite{Bertoldi:08, Nakov:12, Cohn:07}). 

\begin{comment}
Facing a new low resource language pair, several questions arise when trying to use triangulation. 

\begin{itemize}\addtolength{\itemsep}{-0.4\baselineskip}
        \item How large should the triangulated table be?
        \item What is the best way to compute feature values in the triangulated phrase table?
        \item When combining with the direct system, do we use linear interpolation or alternative decoding paths?
        \item Is the approach of cascading a viable option?
        \item How does one penalize triangulated phrase pairs with insufficient alignment between the words in the phrase pairs?
\end{itemize}


All the papers that use triangulation in machine translation cite either \cite{Utiyama:07} or \cite{Cohn:07}, both published in 2007 (and sometimes cite both of them but use either one model or the other). However, these two papers introduce triangulation for phrase-based SMT in very different ways and their models are different from each other. To our knowledge, before this paper there has been no in-depth study of the different choices in building an SMT system using triangulation. Another limitation of the original work in triangulation~\cite{Utiyama:07,Cohn:07} is the unrealistic use of languages with abundant parallel data to simulate low-resource languages. Subsequent work~\cite{Nakov:12,Nakovemnlp:12,Gispert:06,Huck:12} has also assumed that parallel data in pivot languages can be found in the same domain as the original resource-poor language pair. This kind of domain similarity is not easy to find for realistic low-resource settings. In this paper, we consider and answer these design issues for real-world low-resource language pairs, building an effective machine translation for some of these languages for the first time. In constrast, in this dissertation, we improve translation quality by using triangulation through careful consideration of the triangulation design options listed above. Furthermore, in all four languages since the low-resource language pair and pivot language pair data typically come from very different domains, we use insights from domain adaptation to fine-tune the weighted mixture of direct and pivot based phrase pairs to significantly improve translation quality. 

\end{comment}
Having obtained a new source target pair, how best to compute the feature values ? For source phrase src, target phrase tgt and pivot phrase pvt, we can compute the feature values like in~\cite{Utiyama:07} using the following equations : 

 		\begin{equation} \label{eq:first}
                 p_{lex}(tgt \mid src) = \sum_{pvt} p_{lex}(tgt \mid pvt) p_{lex}(pvt \mid src)
        \end{equation}

        \begin{equation}
        	p_{lex}(src \mid tgt) = \sum_{pvt} p_{lex}(src \mid pvt) p_{lex}(pvt \mid tgt)
        \end{equation}

         \begin{equation}
        	p_w(tgt \mid src) = \sum_{pvt} p_w(tgt \mid pvt) p_w(pvt \mid src)
        \end{equation}

        \begin{equation} \label{eq:last}
        	p_w(src \mid tgt) = \sum_{pvt} p_w(src \mid pvt) p_w(pvt \mid tgt)
        \end{equation}

        For all the feature values, we multiply the corresponding values for source pivot and pivot target entries and marginalize over the pivot phrase. Note that we are making an independence assumption shown in equation below. 

         \begin{eqnarray*} \label{eq:independence}
                p(tgt \mid src)&=&\sum_{pvt}{p(tgt, pvt \mid src)}\\
                &=& \sum_{pvt}{p(tgt \mid pvt, src)\,p(pvt \mid src)}\\
                &\approx& \sum_{pvt}{p(tgt \mid pvt)\,p(pvt \mid src)}
        \end{eqnarray*}
        We are assuming that the pivot phrase fully represents the information and thus, neglect the tgt phrase in the equation~\eqref{eq:independence}.


        Multiplying all the features on the source pivot and pivot target is an obvious first way to obtain feature values for the triangulated table. Most previous papers follow the same route for initial scores. As we will see later, using the joint probability and changing the lexical scores leads to small but consistent improvements. 



\newcommand{\maninexample}[1]{\emph{$\grave{a}$ $l\acute{a}$ $b\acute{a}\acute{a}r\acute{a}$ \textipa{\textltailn}$\acute{u}m\acute{a}$ $k\acute{o}s\acute{É”}n$}}

\begin{table*}
\begin{tabular}{p{0.3\linewidth}p{0.7\linewidth}}
\toprule
Source phrase & translations \\
\toprule
\multirow{1}{*}{\maninexample} & for the good job he has accomplished \\
\midrule
\multirow{8}{*}{\maninexample} & her good work \\ & 
the good work \\
& the good work carried out \\
& the good work done \\
& the good work done by \\
& the good work he has done \\
& the good work that \\
& the sound work \\
\bottomrule
\end{tabular}
\caption{1 translation before and 8 after triangulation for a source phrase in Maninkakan}
\label{example:maninkakan}
\end{table*}

In Table~\ref{example:maninkakan}, we see that the source phrase \maninexample has only 1 translation before using triangulation. Note that the training corpus has the word accomplished only once. After using the target phrases in Europarl, we get 8 translations for the same phrase. We also see that ``work'' has changed to ``job'' and the possible target phrases are shorter. 


 



\section{Models}
\label{sec:models}

\subsection{Top-\emph{n} filtering}
\label{subsec:topn}
 The size of the triangulated phrase table is controlled by the number of translations \emph{n} considered for a given source phrase. Consider a source phrase \emph{p$_s$} that translates to \emph{p$_p$} in the pivot language. The phrase \emph{p$_p$} has 1293 translations in the pivot target table. Considering all the 1293 translations will result in 1293 translations for the phrase \emph{p$_s$} via one pivot phrase. It is reasonable to expect the phrase \emph{p$_s$} to have multiple pivot translations, all having a higher number of translations in pivot target. Considering all translations is not recommended for several reasons. Firstly, this will lead to a very large phrase table. Table~\ref{table:allrules} shows the number of rules we can end up with if we consider all possible paths to a target phrase. To put it in perspective, the direct table for Mawukakan and Maninkakan have 51K and 60K phrase pairs respectively. Secondly, alongwith valid translations, triangulation also adds some noise to the translations by considering several translations of the common pivot phrase. Considering all translations would add even more noise to our triangulated phrase table. Having said that, when one has only 5000 parallel sentences for the direct system, how large a value of \emph{n} is enough ? In section~\ref{sec:results}, we report results on n = \{20, 40, 60, 80, 100\}. Figure~\ref{fig:multiplication_factors} shows the increase in the size of the triangulated phrase table when compared to the direct phrase table for all the four languages. For all the four languages, the increase in size of the triangulated table is linear. The difference between n = 20 and say, n = 80, is not surprisingly large. For Mawukakan and Maninkakan, we observe that the initial multiplication factor is much larger than the other two languages, despite having a tiny source pivot corpora.

        \begin{table}
                \footnotesize
                \small
                \centering

                \begin{tabular}{p{0.3\linewidth}p{0.5\linewidth}}
                \toprule
                language &  Rules \\
                \toprule
                maninkakan & 106.7M \\
                mawukakan & 151.6M \\
                \bottomrule
                \end{tabular}
                \caption{Number of rules if all possible paths are considered}
                \label{table:allrules}
        \end{table}


\subsection{Connectivity features}
\label{subsec:connectivity}
        The phrase pairs in the triangulated phrase table are contingent upon the common pivot phrases. As a result, we can have phrase pairs that map ``!'' to a target phrase ``and making the soup thick !'' in Haitian Kreyol to English triangulated phrase table. Computing feature values using equations from section~\ref{subsec:topn}, it is reasonable to assume that spurious phrase pairs like above can get a high enough feature value to end up as a translation during decoding. To reward phrase pairs that have more alignment links between and to penalize pairs that don't, we add two connectivity features to the phrase table, as used in ~\cite{Ahmed:13}.

        For a source phrase \emph{p$_s$}, target phrase \emph{p$_t$}, and with the number of alignment links between them \emph{N}, the strength will be calculated as follows :

        \begin{equation*}
                source_{strength} = \frac{\mathrm{N}}{\mathrm{S}}
        \end{equation*}

        \begin{equation*}
                target_{strength} = \frac{\mathrm{N}}{\mathrm{T}}
        \end{equation*}

        where S is the length of the source phrase \emph{p$_s$} and T is the length of the target phrase \emph{p$_t$}. To compute the connectivity strength feature, the alignments in the source pivot phrase pair are intersected with the pivot target phrase pair. If the resulting alignment has a higher strength, it implies that a majority of the source words do have an alignment with the target.


\subsection{IBM Model1 Alignment}
\label{subsec:model1}

        In section~\ref{subsec:topn}, we computed the lexical scores by multiplying the component scores and marginalizing over the pivot phrase. The component lexical scores are a measure of the word-to-word alignment~\cite{Koehn:03} and by multiplying them, the final lexical scores are implying some strength-of-tie for each pair in the source target translation. But, as was discussed in~\ref{subsec:topn}, using triangulation adds some noise to the translation model by proposing spurious translations.

        An alternative way to compute the lexical score is to use a Model 1~\cite{Brown:1993} score between the phrase pairs in the triangulated table. Treating the triangulated phrase table as a parallel corpus, we learn the model 1 alignment scores in both directions using 5 iterations of the EM algorithm~\cite{Dempster:77}. Given a foreign sentence $f = f_{1} \ldots f_{m}$, english sentence $e = e_{1} \ldots e_{l}$, the model 1 score between the sentences is calculated as follows:

                \begin{equation}
                        p(f, a \mid e) = \frac{\epsilon}{(l+1)^m}\mathlarger{\prod\limits_{j=1}^{m}t(f_{j}|e_{a(j)})}
                \end{equation}

        The strength features in section~\ref{subsec:connectivity} assign a phrase-level score to a given translation pair. The score does not reflect the actual many-to-one alignments between the phrases. A Model 1 score learns the likelihood of the alignment of the individual words, while also considering the fact that a triangulated table will have less number of source phrases translating into good and some noisy translations. Noisy translations will automatically get a lower Model 1 score, something less likely to happen when using the simpler approach of multiplying the lexical scores. This effect of noisy translations ending up as a viable translation during decoding is also because of the limited source pivot training corpora available. Several translations have been only seen once and the phrase lengths are not very long either ( 90\% of Mawukakan and Maninkakan phrase table has less than or equal to 3 words). A modified model 1 score is also used in~\cite{Cohn:07} in the absence of word alignments. They report a BLEU score improvement of 2 points over the standard feature set when using the Model 1 score, but we observe a different pattern altogether across all the four resource-poor languages which is explained in more detail in Section~\ref{sec:results}.

\subsection{Joint and Conditional Distributions}
\label{subsec:joint}

Another way of calculating the triangulated phrase scores $p_{tr}(e \mid f)$ and $p_{tr}(f \mid e)$ would be to take the joint probability $p_{tr}(s, t)$ and decompose it to get the conditional distributions. But, we do not have the counts in the triangulated phrase table. The pairs that end up in the triangulated table are contingent on the common pivot phrases that connected the source target pair, thus, counting the pairs after triangulation will not be a true reflection of the joint probability. For a triangulated table between \emph{src} and \emph{tgt}, using source pivot table \emph{sp} and pivot target table \emph{pt}, we can compute the joint probability of a phrase pair (s, t) as follows:

        \begin{eqnarray*}
                p_{tr}(s, t) &=& \sum_{i}p_{sp}(s, i) p_{pt}(i, t) \\
                                &=& \sum_{i}p_{sp}(s \mid i) p_{sp}(i) p_{pt}(i \mid t) p_{pt}(t)
        \end{eqnarray*}



This is a more accurate description of the joint probability of the (s, t) phrase pair in the triangulated table because we are using source pivot and pivot target counts, both of which have been extracted from the alignments.

We compute $p_{sp}(s, i)$ using equation~\eqref{eq:joint} 

\begin{equation} \label{eq:joint}
	p_{sp}(s, i) = p_{sp}(s \mid i) p_{sp}(i)
\end{equation}

	

 As we have the counts for the direct system, computing the joint and the conditional distributions is relatively straight-forward. When interpolating the triangulated and direct translation models~\eqref{eq:interpolation}, the three new features are added to the log-linear pipeline. Owing to the smaller size of the source pivot corpora, we observed it was better to add the three new features to the log-linear pipeline and let MERT decide which features lead to a better BLEU score. This is in contrast to~\cite{Cohn:07} where they combine the joint probability of the phrase pair from direct and triangulated uniformly, and use the resulting conditionals as part of the log-linear pipeline.


\section{Translation Model Combination}
\label{sec:interpolation}
Combining translation models, trained on corpora from different domains, is an inherently difficult task. We want to make our translations better on the domain of the test set, while also correcting errors in our baseline translation model. In case of low-resource languages, the baseline translation model has been trained on completely out-of-domain corpora or some in-domain and a lot of out-of-domain corpora. This results in translation pairs that are missing altogether or translation pairs with so low probability that decoding misses them altogether. The aim of Interpolation is to add translation pairs that are missing and give more weightage to translations that are more valid in the given domain. 

	Consider the translations from Haitian-Creole to English. We have a baseline model trained on a little in-domain parallel data (\~17K sentences). We aim to make our translations better on the same domain using a lot of out-of-domain data, which in our case is parlimentary proceedings. Its important that we do not make the baseline model translations end up at the bottom of the stack because they are in-domain. At the same time, we do not want to miss out on the valid translations introduced by the larger, clean parliamentary proceedings based translation model. 

	\subsection{Example}
		Consider a phrase pair, (jan nou, that you). Each phrase pair has a set of scores associated with it in the phrase table. They are the forward and backward lexical probabilities, and the forward and backward phrase probabilities. 

		From the direct phrase table, we have the following scores for the phrase pair mentioned above. The last score, 2.718, is a constant which is the phrase penalty. 
	\begin{verbatim}
		jan nou  ||| that you ||| 0.000786782 2.11603e-05 0.125 0.00906772 2.718 
	\end{verbatim}

		The triangulated table also happens to have the same phrase pair with different scores. These scores have been obtained by using the equations shown above.
	\begin{verbatim}
		jan nou ||| that you ||| 0.00318015 7.75194e-05 0.0715829 0.00214831 2.718
	\end{verbatim}

		We know that our direct system has been trained on in-domain data, hence, it should get more weightage intuitively. A heuristic approach to this problem would choose a pair of values and see which one does best. For instance, if you choose 0.85 for the direct table and 0.15 for the triangulated table, the end result for the phrase pair would look like the following : 

	\begin{verbatim}
		jan nou ||| that you ||| 0.0011457872 2.961416503e-05 0.116987435 0.00802980849 2.718	
	\end{verbatim}

		There are several flaws with the approach outlined above. Firstly, an intuitive idea about the importance of the in-domain or out-of-domain phrase table is not enough. The direct Haitian-creole to English phrase table has been trained on only 120K parallel sentences and cannot always be right. Hence, starting with 0.9 for the direct table and 0.1 for the triangulated table is an extreme step. So is 0.5 and 0.5 because we want translations with more influence from the cleaner, larger Europarl data. Moreover, as we will discuss in the other chapters, we report results on several combinations of triangulation, based on changes in phrase scores, lexical scores and adding connectivity features. With every improvement, the importance of the triangulated table might increase or decrease. The heuristic approach will not be able to take that into account. 

		We use CONDOR to perform an efficient grid search over the pairs of co-efficients based on the BLEU score of the interpolated system on the heldout set. Our intepolation method would have the steps outlined in Algorithm~\ref{algo:condor}
 
		
        For instance, consider the word ``tranblemannt\`e''. It gets translated to \emph{shaking} by our best baseline system. After interpolating our top-20 triangulated translation model, it gets translated to earthquake. Note that the word earthquake is present in the baseline translation model but does not end up as a translation for the source word ``tranblemannt\`e".


        \begin{equation} \label{eq:interpolation}
                p_{interp}(s \mid t) = \lambda_{d} p_{d}(s \mid t) + (1 - \lambda_{d}) p_{t}(s \mid t)
        \end{equation}

        Given a source target phrase pair (s, t), we use uniform linear interpolation as shown in~\eqref{eq:interpolation}to scale all the feature values. 
         \begin{algorithm}
                \small
                \caption{Grid Search for Interpolation}
                \label{algo:condor}
                \textbf{Input:} triangulated phrase table p$_{t}$, \\ direct phrase table p$_{d}$, \\
                $\lambda_{d}$, $\lambda_{t} = 1 - \lambda_{d}$, prev$_{bleu}$ = 0, \\
                minimum = $e ^{-2}$ \\
                \textbf{Output:} best$_{\lambda_{d}}$


                \begin{algorithmic}[l]
                        \WHILE{$\delta_{bleu}$ $>$ minimum} \label{aline:condition}
                        \STATE{interpolate p$_{d}$, p$_{t}$ to give p$_{interp}$} \label{aline:inter}
                        %\STATE{p$_{interp}$  = $\lambda_{d}$$p_{d}$ + $\lambda_{t}$$p_{t}$}
                        \STATE{Run MERT using p$_{interp}$ as translation model}
                        \STATE{find bleu$_{heldout}$}
                        \STATE{$\delta_{bleu}$ = bleu$_{heldout}$ - prev$_{bleu}$}
                        \STATE{prev$_{bleu}$ = bleu$_{heldout}$}
                        \STATE{Based on $\delta_{bleu}$, find new$\lambda_{d}$} \label{aline:search}
                        \ENDWHILE
                       \end{algorithmic}
        \end{algorithm}

       Algorithm~\ref{algo:condor} explains the process of using CONDOR~\cite{condor-practice} to find the best interpolation co-efficient for a given direct and triangulated model. Note that the approach can be easily extended to multiple triangulated models. Line~\ref{aline:inter} interpolates the two translation models using equation~\eqref{eq:interpolation}. We re-tune the log-linear weights using MERT for the interpolated feature values and use the tuned model to find BLEU score on the heldout set. Based on the difference between the BLEU score obtained and the previous BLEU(line~\ref{aline:search}), CONDOR searches for the new co-efficient in the corresponding direction. The search will culminate when consecutive BLEU scores show a marginal difference(Line~\ref{aline:condition}). As can be seen in the figure ~\ref{fig:condor}, we started with a value of 0.85 for the direct system from Mawu to English. This got a BLEU score of 10.21. If we had taken a heuristic approach, we would have just taken 0.50 and 0.50, and stopped. Alternatively, we might have tried 0.50, 0.60, 0.70 and 0.80~\cite{Nakov:12}, keeping in mind the different domains. But, neither strategy would have helped us reach our best BLEU score of 10.91, observed with $\lambda_{d}$ = 0.612962. If we use uniform weights for both the tables, we get BLEU scores on heldout as shown in Table~\ref{table:all_results}. In three of four cases, we would not have out-performed our baseline.


\anoop{chapter ends abruptly. perhaps have a short summary section?}

