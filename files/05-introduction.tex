%!TEX root=/home/ska124/Dropbox/Thesis/thes-full.tex
%% Copyright 1998 Pepe Kubon
%%
%% `05-introduction.tex' --- 1st chapter for thes-full.tex, thes-short-tex from
%%                the `csthesis' bundle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%       Chapter 1 
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}
\label{sec:introduction}

\section{Why study Low-Resource?}
\label{sec:low_resource}
Statistical Machine Translation(SMT) has enabled several languages like French, Spanish, Finnish and others to have publicly available translation systems which can translate from and into these languages. Google Translate has 81 languages you can translate from and to. In 2003, we had none ! 


Having said that, more than 90\% of the World languages do not have a publicly available SMT system. Moreover, most of them have not been studied in the SMT literature before. In Table~\ref{table:numberspeakers}, we observe that the major languages have way more number of speakers than the languages we study in this disseration. 
\begin{table*}
	\begin{tabular}{lr}
	\toprule
	Language & \#speakers \\
	\toprule
	French & 120M \\
	Spanish & 466M \\
	Mandarin Chinese & 1026M \\
	\midrule
	Haitian Kreyol & 12M \\
	Malagasy & 18M \\
	Mawu & 2M \\
	Manin & 2M \\
	\bottomrule
	\end{tabular}
	\caption{Number of speakers for Major and low-resource languages}
	\label{table:numberspeakers}
	%\small
	%\centering
\end{table*}


All the four languages we study also throw up interesting linguistic challenges that are not always seen in the major languages. For instance, Malagasy has influence from French and Arabic. While there are some loan words from French, the numbers are written right-to-left like Arabic. It also shows vocabulary overlap with Bantu. Diacritics are used but only in certain circumstances. On the other hand, Mawukakan and Maninkakan show a more frequent usage of diacritics. But the accent can be different depending on the placement of the word. Haitian Kreyol is a French-based Creole but does not share any vocabulary with Parisian French. The influence is from 18th century French where Haiti was ruled by France. Haitian Kreyol became an official language only in 1961. Like is typical of Creoles, the language shares some characteristics (e.g word order) with French but the vocabulary has undergone change according to the local dialects. Studying low-resource languages will take us further towards the quest for a universal translator. 

\section{Pipeline}
To the interested reader, we refer to the comprehensive and readable SMT survey~\cite{Lopez07asurvey}. Below, we discuss the pipeline for phrase-based SMT~\cite{Koehn:03} which has been used for all the experiments in the dissertation, and discuss how a low-resource language pairs raises question at each stage. 

SMT uses data-driven models to translate sentences in a source language to a given target language. Given a parallel corpus between \emph{s} and \emph{t}, a phrase-based SMT system has a generic pipeline that looks as described in Algorithm~\ref{algo:pbsmt}. 

\begin{algorithm}
\small
%\centering
\caption{Building a phrase-based system}
\label{algo:pbsmt}
\textbf{Input}: Parallel corpus between \emph{s} and \emph{t} \\
\textbf{Output}: A translation model ``tm'' 
\begin{algorithmic}[l]
	%\STATE{\textbf{Clean:}Pre-process both sides of the corpus} \label{aline:preprocess}
	\STATE{\textbf{Alignments: }Learn bi-directional alignments} \label{aline:alignments}
	\STATE{\textbf{Extraction: }Extract phrase pairs from alignments and compute likelihoods for each translation pair} \label{aline:scores}
	\STATE{\textbf{Tuning: }Set weights for features by maximizing BLEU score on a development set using MERT} \label{aline:MERT}
	\STATE{\textbf{Decoding: }Using language model and translation model, translate test sentences} \label{aline:decoding}
\end{algorithmic}
\end{algorithm}

The reason its called phrase-based SMT is because the base unit of translation are \emph{phrases}. The phrases need not be linguistically motivated. Phrases in this context means a group of words. In this dissertation, we only use phrase-based SMT for all the experiments but there are others in the literature.  \alert{cite Galley, Chiang and anybody else if needed} 

Each step of Algorithm~\ref{algo:pbsmt} outlined above raises questions when faced with a low-resource language pair. Low-resource languages are those with insufficient resources to use for Machine Translation into and/or from the language. To provide perspective, French has a corpus with $10^9$ parallel sentences with English. On the other hand, the language with the highest amount of data in this dissertation is Haitian Kreyol, with 121K sentences. Out of those 121K, only 16\% are from the target domain, the sentences are noisy and with punctuation and spelling mistakes.


Lets consider each step and discuss the problems that come up. Given parallel data, the goal of the alignment models~\cite{Brown:1993,Vogel:1996} is to learn which word in source language \emph{s} translates to target language \emph{t} and assign a likelihood to the pair of words. The advanced alignment models use initial alignments from IBM Model 1. Model 1 starts with uniform initialization and uses Expectation Maximization~\cite{Dempster:77} to converge. Facing a corpus of a small size, the alignment models will end up making inferences that are not always true. They will place higher likelihood on pairs seen fewer number of times due to lack of more data. The phrase extraction step(Line~\ref{aline:scores}) looks at alignments learnt from Line~\ref{aline:alignments} in both directions and determines which phrases can translate from one language to another using the intersection of the alignments. At the end of this step, we have a phrase table which has rules of the following form : 

\begin{table*}[ht]
\small
\small
\centering
\begin{tabular}{p{0.3\linewidth}p{0.2\linewidth}p{0.4\linewidth}}
\toprule
src & tgt & features \\
\toprule
! la situacion de haiti & concerned about the situation in haiti & 0.5 8.16237e-09 1 0.000483004 2.718 \\
\bottomrule
\end{tabular}
\caption{Example of a phrase pair in the Haitian Kreyol to English table}
\label{table:example_rule}
\end{table*}

The table~\ref{table:example_rule}  says that the source phrase ``! la situacion de haiti , '' translate to the target phrase ``concerned about the situation in haiti ,'' with the feature values shown on the right. 

\begin{table*}
	\small
	\small
	%\centering
	\begin{tabular}{p{0.3\linewidth}p{0.6\linewidth}}
	\toprule
	Feature &  Explanation \\
	\toprule
	$p_{w}(f \mid e)$ & probability of seeing phrase ``f'' given ``e'' \\
	$p_{lex}(f \mid e)$ & lexical probability of seeing phrase ``f'' given ``e'' \\
	$p_{w}(e \mid f)$ & probability of seeing phrase ``e'' given ``f'' \\
	$p_{lex}(e \mid f)$ & lexical probability of seeing phrase ``e'' given ``f'' \\
   	phrase penalty & a constant value penalizing distortion \\
	\bottomrule
	\end{tabular}
	\caption{Features of the phrase pairs, where ``f'' is foreign/source \& ``e'' is target/english}
	\label{table:features}
\end{table*}

The 5 features are mentioned in Table~\ref{table:features}. The two $p_{w}$ are the phrasal features, features that determine the likelihood of the source phrase translating to target and vice-versa. The phrasal translation likelihood is computed by using relative frequencies, as shown in equation~\eqref{eq:trans}.

\begin{equation} \label{eq:trans}
	p_{w}(f \mid e) = \frac{c(f, e)}{\mathlarger{\sum\limits_{\grave{f}}}c(\grave{f}, e)}
\end{equation}

The counts referred to in equation~\eqref{eq:trans} are obtained from the alignments. Note that the alignment models that were learnt on the smaller corpus will cause some propagation of errors in the phrasal probabilities. 

The lexical features~\cite{Koehn:03} are actually computed as shown in equation~\eqref{eq:lex} : 

\begin{equation} \label{eq:lex}
	p_{lex}(f \mid e, a) = \prod\limits_{i=1}^{n} \frac{1}{\{j | (i,j) \in a\}}
	\mathlarger{\sum\limits_{\forall (i,j) \in a}} w(f_{i} \mid e_{j})
\end{equation}


The intuition behind having a pair of lexical features is to reward syntactic phrases while penalizing spurious ones. As shown in equation~\eqref{eq:lex}, the lexical probability is the product of the lexical alignment probabilities of the constituent words in the phrase table. Hence, if a longer source phrase aligns to an equally long target phrase, it can be penalized if the individual words are not aligned. 

Having learnt translation pairs with their respective features, we now want to know which features are better indicators of good translations and vice-versa. For weight learning, we use Minimum Error Rate Training. Before discussing MERT, its important to know about BLEU~\cite{Papineni:02}, Bilingual Evaluation Understudy. BLEU is the error metric used most often when comparing output translations with reference translations. \alert{discuss BLEU for one or two sentences}

Minimum Error Rate Training chooses weights for features that minimize BLEU score loss given a ``tuning'' set. A ``tuning'' set is a set of parallel sentences between source and target that is in the same domain as the test and of the same type. For instance, when trying to improve translations for Haitian Kreyol short messages, we have tuning and test in the same domain, SMS. Although our training is 85:15 mix of OOD:SMS. Essentially, MERT takes translation pairs generated from a mixture of domains corpus and tunes the weights such that the translations are more like that target domain. As our training rules have been extracted from a smaller corpora that has not been manually sentence-aligned, MERT is learning weights for features that have values which are not always true. This is why we re-tune our weights for the interpolated model after obtaining a translated table with scaled values from the much larger fr-en table. 

Having obtained the weights and a language model on the target side, decoding refers to the process of finding the best translation for the source sentence as shown in equation~\eqref{eq:decoding}. 

\begin{equation} \label{eq:decoding}
	e_{best} = argmax_{e} \mathlarger{\prod\limits_{i=1}^I} \phi(\hat{f}_{i} | \hat{e}_{i})p_{LM}(e)d(start_{i} - end_{i-1}-1)
\end{equation}

Phrase-based SMT has been used with great success before in the literature. But, as described above, the approach is very data-driven and it is not clear how to achieve fluent translations with only a little parallel data. 


The approach of triangulation~\cite{Cohn:07,Utiyama:07,Nakov:12} aims to add translations for new source phrases while also improving translations for existing source phrases. New source phrases can be added if one has a rich source pivot corpora that leads to a new target phrase in the pivot target corpus. In a low resource scenario, its important to achieve both aims with triangulation. Owing to less training data, the direct system has several out-of-vocabulary(OOV) words. We aim to reduce the number by using triangulation. But, in case of Haitian Kreyol and Malagasy, where our source pivot corpus is completely disjoint and out-of-domain with the direct and pivot target system, we also aim to improve the translations of existing phrases. As we will show in section ~\ref{sec:results}, we do improve translations for both.  


\section{Dissertation Outline}
\label{sec:outline}
Chapter~\ref{chapter:reality} describes the four low-resource languages we study followed by the models and results. \alert{add the chapter about Europarl}.

\section{Contributions}
\label{sec:summary}
We conduct the first in-depth study of triangulation, the first using four real low-resource languages with realistic data settings. As part of the dissertation, we also build the first translation systems for three of the four languages. Our best Haitian-Creole system outperform the best system from the Sixth Workshop on Machine Translation, 2011. 


\section{Setup}
\label{sec:setup}


Moses~\cite{Koehn:07} was used for all the experiments. To build our baseline systems, we followed the standard set of steps: generated bi-directional alignments using GIZA++ ~\cite{OchNey:03}, followed by phrase extraction using the --grow-diag-final-and heuristic. The decoder parameters were optimized using Minimum Error Rate Training ~\cite{Och:03} by minimizing BLEU loss on a development set. All scores reported are case-insensitive BLEU~\cite{Papineni:02}. All language models were generated using SRILM~\cite{Stolcke:02}.~\cite{Ken:11} was used for language model scoring when decoding.