%!TEX root=/home/ska124/Dropbox/Thesis/thes-full.tex
%% Copyright 1998 Pepe Kubon
%%
%% `05-introduction.tex' --- 1st chapter for thes-full.tex, thes-short-tex from
%%                the `csthesis' bundle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%       Chapter 1 
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}
\label{sec:introduction}


\section{Dissertation Outline}
\label{sec:outline}


\section{Contributions}
\label{sec:summary}



\section{Setup}
\label{sec:setup}


We use Moses ~\cite{Koehn:07} for all the experiments. To build our baseline systems, we followed the standard set of steps: generated word alignments using GIZA++ ~\cite{OchNey:03}, followed by phrase extraction. The decoder parameters were optimized using Minimum Error Rate Training ~\cite{Och:03}. We used two language models for the experiments with Haitian-Creole. A 5-gram language model was generated using the english side of the WMT data and another 5-gram language model was generated by combining the english side of WMT with english side of fr-en europarl. The latter was used for all the triangulation and interpolation experiments as triangulation used the europarl corpus of fr-en. Both  language models were generated using SRILM ~\cite{Stolcke:02}. All scores reported are case-insensitive BLEU ~\cite{Papineni:02}. The development, held-out and test sets used for reporting scores are the same as used for the WMT experiments.